{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32958db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "import sqlite3 as sq3\n",
    "from pandas.io import sql\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pyperclip as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c5ca1",
   "metadata": {},
   "source": [
    "## get_urls()\n",
    "- gets the list of urls to detail pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667e3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_Africa_ME = 'https://www.emerics.org:446/newsBrief.es?currentPage={}&pageCnt=50&search_area=2&mid=a10100000000&systemcode=05&search_region=&search_option=ALL&search_year=&search_month=&search_keyword='\n",
    "HTML_Russia_Asia = 'https://www.emerics.org:446/newsBrief.es?currentPage={}&pageCnt=50&search_area=2&mid=a10100000000&systemcode=04&search_region=&'\\\n",
    "                    'search_option=ALL&search_year=&search_month=&search_keyword='\n",
    "HTML_Latin_America = 'https://www.emerics.org:446/newsBrief.es?currentPage={}&pageCnt=50&search_area=2&mid=a10100000000&systemcode=06&search_region=&'\\\n",
    "                      'search_option=ALL&search_year=&search_month=&search_keyword='\n",
    "HTML_CE_Europe = 'https://www.emerics.org:446/newsBrief.es?currentPage={}&pageCnt=50&search_area=2&mid=a10100000000&systemcode=07&search_region=&search_option=ALL&search_year=&search_month=&search_keyword='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62fa69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(html_link):\n",
    "    page = 1\n",
    "    url_list = []\n",
    "    max_page = 1\n",
    "    \n",
    "    #find the maximum number of pages\n",
    "    driver.get(html_link.format(page))\n",
    "    get_total_articles = driver.find_element('xpath','//span[@class=\"floatL count\"]').text\n",
    "    page1 = get_total_articles.split(' ')[1]\n",
    "    page2 = int(page1.split('ê°œ')[0])\n",
    "    if (page2%50 == 0):\n",
    "        max_page = int(page2/50)\n",
    "    else:\n",
    "        max_page = int(page2/50) + 1\n",
    "    \n",
    "    while(max_page >= page):\n",
    "        driver.get(html_link.format(page))\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        li = driver.find_elements('xpath','//*[@id=\"content_detail\"]/div[2]/ul/li')\n",
    "        \n",
    "        for each in li:\n",
    "            a = each.find_element('xpath','div/p[1]/a')\n",
    "            url = a.get_attribute('href')\n",
    "            url_list.append(url)\n",
    "\n",
    "        if (len(url_list) >=0 & len(url_list)%50 == 0):\n",
    "            page += 1\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02e5db",
   "metadata": {},
   "source": [
    "## Save URL list into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "186ecb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveURLs(url_list, file_name):\n",
    "    # open file in write mode\n",
    "    with open(file_name, 'w') as fp:\n",
    "        for url in url_list:\n",
    "            # write each item on a new line\n",
    "            fp.write(\"%s\\n\" % url)\n",
    "        print('URLs saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848cd01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readURLs(file_name):\n",
    "    # empty list to read list from a file\n",
    "    urls = []\n",
    "    # open file and read the content in a list\n",
    "    with open(file_name, 'r') as fp:\n",
    "        for line in fp:\n",
    "            # remove linebreak from a current name\n",
    "            # linebreak is the last character of each line\n",
    "            x = line[:-1]\n",
    "\n",
    "            # add current item to the list\n",
    "            urls.append(x)\n",
    "    return(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7fc7d8",
   "metadata": {},
   "source": [
    "## remove_punc()\n",
    "- removes punctuations from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26a4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(data):\n",
    "\n",
    "    punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~â€œâ€Â·ã€Œã€â–³ã€Šã€‹â—¦â€¢â—¦ã†â€˜â€™â—‹ââ–¡â˜â– â€»âœ”ï¸â–·â‘ â‘¡â‘¢â‘£ã€ã€‘ğŸ¡ğŸ‘‘ğŸ”’ğŸ’£ğŸ›¡ï¸ğŸ”»ğŸŒŒğŸ”¥ğŸš¢ğŸ”‘ğŸ‘€â€¦â–¶ã…‡ã€âˆ™ã€Â·-â€œâ€â–²I]'\n",
    "    new_string = re.sub(punc, '', data) # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    new_string2 = re.sub('\\n', ' ', new_string) # newline ì œê±°\n",
    "    new_string3 = re.sub('\\\\s+', ' ', new_string2) # multiple spaces ì œê±°\n",
    "    return new_string3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700b4c8",
   "metadata": {},
   "source": [
    "## db_save()\n",
    "- saves data as db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71e7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_save(ARTICLE_LIST, db_name, table_name):\n",
    "    with sq3.connect(os.path.join('.',db_name)) as con: # sqlite DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° íŒŒì¼ìƒì„±\n",
    "        try:\n",
    "            ARTICLE_LIST.to_sql(name = table_name, con = con, index = False, if_exists='replace') \n",
    "            #if_exists : {'fail', 'replace', 'append'} default : fail\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "        print(len(ARTICLE_LIST), 'ê±´ ì €ì¥ì™„ë£Œ..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4ab56",
   "metadata": {},
   "source": [
    "## db_select()\n",
    "- read data from db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24142f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_select(db_name, table_name):\n",
    "    with sq3.connect(db_name) as con: \n",
    "        try:\n",
    "            query = 'SELECT * FROM {}'.format(table_name)\n",
    "            df = pd.read_sql(query, con = con)\n",
    "        except Exception as e:\n",
    "            print(str(e)) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29504e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_delete(db_name, table_name):\n",
    "    with sq3.connect(db_name) as con: \n",
    "        try:\n",
    "            cur = con.cursor()\n",
    "            sql = 'DELETE FROM {}'.format(table_name)\n",
    "            cur.execute(sql)\n",
    "        except Exception as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221c3dd",
   "metadata": {},
   "source": [
    "## get_info()\n",
    "- returns detailed information on the article pages as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b200b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(url):\n",
    "    details = []\n",
    "    articles = []\n",
    "    articleString = \"\"\n",
    "    \n",
    "    driver.get(url)\n",
    "    title = driver.find_element('xpath','//*[@id=\"content_detail\"]/div[1]/div/div/h2').text\n",
    "    country = driver.find_element('xpath','//*[@id=\"content_detail\"]/div[1]/div/div/p[2]/span[1]').text\n",
    "    date = driver.find_element('xpath','//*[@id=\"content_detail\"]/div[1]/div/div/p[2]/span[3]').text\n",
    "    article = driver.find_element('xpath','//*[@class=\"view-content\"]').text\n",
    "    #p = article.find_elements('xpath','text')\n",
    "    \n",
    "    #for each in p:\n",
    "    #    articles.append(each)\n",
    "    #articleString = ' '.join(articles)\n",
    "    \n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    #words = remove_punc(articleString)\n",
    "    words = remove_punc(article)\n",
    "    details.append(title)\n",
    "    details.append(country)\n",
    "    details.append(date)\n",
    "    details.append(words)\n",
    "    \n",
    "    return details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd1844",
   "metadata": {},
   "source": [
    "## db_save_as_csv()\n",
    "- saves dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a568cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_save_as_csv(data):\n",
    "    data.to_csv(\"ì‹ í¥ì§€ì—­ì •ë³´_ì¢…í•©ì§€ì‹í¬íƒˆ2.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db88bf2",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------------------------------------------------------------\n",
    "# Main\n",
    "This is the main part which uses functions to read articles and saves the data as csv file\n",
    "### ---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2473d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12936\\2300451305.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('C:/Users/chromedriver_win32/chromedriver.exe', chrome_options = options) #ë“œë¼ì´ë²„ê²½ë¡œ ì§€ì •\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12936\\2300451305.py:8: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome('C:/Users/chromedriver_win32/chromedriver.exe', chrome_options = options) #ë“œë¼ì´ë²„ê²½ë¡œ ì§€ì •\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions() \n",
    "#options.add_argument(\"--start-maximized\");  # Chrome ë¸Œë¼ìš°ì € ìµœëŒ€í™” ì„¤ì •\n",
    "#options.add_argument('--headless')  # headless ëª¨ë“œ\n",
    "options.add_argument('--disable-gpu')  # ê·¸ë˜í”½ ê°€ì† í•´ì œ (ì˜¤ë¥˜ ë°©ì§€)\n",
    "#options.add_argument('--mute-audio')  # ìŒì†Œê±°ëª¨ë“œ ì ìš©\n",
    "\n",
    "#driver = webdriver.Chrome('service = Service(ChromeDriverManager().install())', options = options)\n",
    "driver = webdriver.Chrome('C:/Users/chromedriver_win32/chromedriver.exe', chrome_options = options) #ë“œë¼ì´ë²„ê²½ë¡œ ì§€ì •\n",
    "\n",
    "\n",
    "## -----------------------------------------------------------------------\n",
    "# urls for Africa\n",
    "#urls = get_urls(HTML_Africa_ME)\n",
    "#URL_FILE = 'url_list_africa.txt'\n",
    "#TABLE_NAME = 'emerics_Africa'\n",
    "## -----------------------------------------------------------------------\n",
    "# urls for Russia & Asia\n",
    "urls = get_urls(HTML_Russia_Asia)\n",
    "URL_FILE = 'url_list_russia_asia.txt'\n",
    "TABLE_NAME = 'emerics_Russia_Asia'\n",
    "## -----------------------------------------------------------------------\n",
    "# urls for Latin America\n",
    "#urls = get_urls(HTML_Latin_America)\n",
    "#URL_FILE = 'url_list_latin_america.txt'\n",
    "#TABLE_NAME = 'emerics_Latin_America'\n",
    "## -----------------------------------------------------------------------\n",
    "# urls for Central East Europe\n",
    "#urls = get_urls(HTML_CE_Europe)\n",
    "#URL_FILE = 'url_list_ce_europe.txt'\n",
    "#TABLE_NAME = 'emerics_CE_Europe'\n",
    "\n",
    "saveURLs(urls, URL_FILE)          # save urls to txt file\n",
    "url_list = readURLs(URL_FILE)     # read urls from txt file\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for url in url_list:\n",
    "    details = get_info(url)\n",
    "    \n",
    "    df = pd.DataFrame([{\n",
    "        \"ì œëª©\": details[0],\n",
    "        \"êµ­ê°€\": details[1],\n",
    "        \"ë‚ ì§œ\": details[2],\n",
    "        \"ë³¸ë¬¸\": details[3]\n",
    "    }])\n",
    "    \n",
    "    df_list.append(df)\n",
    "    driver.implicitly_wait(4)\n",
    "    time.sleep(1)\n",
    "\n",
    "ARTICLE_LIST = pd.concat(df_list)\n",
    "\n",
    "db_save(ARTICLE_LIST, 'ì‹ í¥ì§€ì—­ì •ë³´_ì¢…í•©ì§€ì‹í¬íƒˆ2.db', TABLE_NAME)\n",
    "db_save_as_csv(ARTICLE_LIST)\n",
    "\n",
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = db_select('ì‹ í¥ì§€ì—­ì •ë³´_ì¢…í•©ì§€ì‹í¬íƒˆ2.db', TABLE_NAME)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f021a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
